{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under The Hood: ColumnTransformers in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ColumnTransformers coupled with Pipelines are great tools to manage features before training a model. Sadly, its over-complicated documentation of usage isn't that great. With a trivial dataset, I demonstrate how ColumnTransformers can be used without hassle and what happens under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the sklearn library, one most definitely struggles with transforming the features before model training. ‘Transforming’ in this context means:\n",
    "- Scaling (e.g. MinMax, Standard etc) for numerical variables\n",
    "- Encoding (e.g. Ordinal, OneHot, with an option to avoid the dummy variable trap) for the categorical variables\n",
    "- Imputing (e.g Simple mean) the missing data points\n",
    "\n",
    "A ColumnTransformer is great at seamlessly doing these 3 - for example, you need not separate the categorical features from numerical, process them separately and join them back. ColumnTransformer does this for you in a single flow using a Pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, ColumnTransformers do way too much with too less. In this document I will explore the inner workings of ColumnTransfomers and answer questions like:\n",
    "- How to best manage categorical and numerical variables? Is it necessary to use a ColumnTransformer?\n",
    "- In what order does ColumnTransformer process columns? \n",
    "- How to keep track of lost column names since a ColumnTransformer returns a numpy nd-array?\n",
    "- What if there are other variables in my dataset which are not model features but are required to be retained?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to manage variables is to have two separate lists- one containing the names of categorical variables, the other containing the names of numerical variables. (Tip: It’s even better to carry them together in a dictionary.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['income', 'age']\n",
    "categorical_columns = ['class', 'gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a large DataFrame, you can create these two lists by looking at the `dtypes` and sending the `int`/`float` type variables to `numeric_columns` and the object type variables to `categorical_columns`. \n",
    "\n",
    "In case this doesn’t work out and you have categories that are numbered, it’s best to use a YAML file to manually keep a record of all the model variables under suitable headings/keys. Creating a YAML would just be a one-time effort.\n",
    "\n",
    "Note: Unless specified, encoding functions create encoded categories in the alphabetic order (so you can expect to see `gender_F` and then `gender_M` for `gender`).\n",
    "\n",
    "Now create separate pipes for each list.\n",
    "Note: The syntax of creating a sklearn pipe is (Name, Transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "categorical_pipe = Pipeline([(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "numerical_pipe = Pipeline([(\"scale\", MinMaxScaler())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid the dummy variable trap while using linear models, use:\n",
    "`drop_first = True` instead of `handle_unknown=\"ignore\"` in OHE.\n",
    "\n",
    "Now define the ColumnTransformer in the format (Name, Object, Columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = ColumnTransformer([(\"cat\", categorical_pipe, categorical_columns),    \n",
    "(\"num\", numerical_pipe, numeric_columns),\n",
    "], remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit` and `transform` methods can now be invoked on a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.         0.         1.         0.\n",
      "  1.        ]\n",
      " [0.         1.         0.         1.         0.         0.8\n",
      "  0.38888889]\n",
      " [0.         0.         1.         1.         0.         1.\n",
      "  0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5         6\n",
       "0  1.0  0.0  0.0  0.0  1.0  0.0  1.000000\n",
       "1  0.0  1.0  0.0  1.0  0.0  0.8  0.388889\n",
       "2  0.0  0.0  1.0  1.0  0.0  1.0  0.000000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.DataFrame({ 'income': [100,500,600],\n",
    "                        'age': [23,12, 5],\n",
    "                      'class': [6,7,8],\n",
    "                      'gender': ['M','F','F']})\n",
    "preprocess = preprocess.fit(train)\n",
    "train_transformed = preprocess.transform(train)\n",
    "print(train_transformed)\n",
    "pd.DataFrame(train_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you can straightaway do `train_transformed = fit_transform(train)` but this won’t provide you with the preprocess object you _should_ be having for transforming the validation and test sets.\n",
    "Notice that `train_transformed` is returned as an nd-array (something you don’t want) with column information lost.\n",
    "\n",
    "The workaround for this is the function `get_transformer_feature_names(columnTransformer)`\n",
    "\n",
    "Credits: https://stackoverflow.com/questions/57528350/can-you-consistently-keep-track-of-column-labels-using-sklearns-transformer-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class_6', 'class_7', 'class_8', 'gender_F', 'gender_M', 'income', 'age']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_transformer_feature_names(columnTransformer):\n",
    "\n",
    "    output_features = []\n",
    "\n",
    "    for name, pipe, features in columnTransformer.transformers_:\n",
    "        if name!='remainder':\n",
    "            for i in pipe:\n",
    "                trans_features = []\n",
    "                if hasattr(i,'categories_'):\n",
    "                    trans_features.extend(i.get_feature_names(features))\n",
    "                else:\n",
    "                    trans_features = features\n",
    "            output_features.extend(trans_features)\n",
    "\n",
    "    return output_features\n",
    "\n",
    "get_transformer_feature_names(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But then you ask, what about the order of the columns? How am I sure the columns are rightly named and there is no mix up?\n",
    "The answer to this is: you need not worry. The column order within categorical and numerical variables will be **exactly** as declared in the two initial lists and the ColumnTransformer will not mess with the ordering **at all**. And as for the arrangement of the numerical and categorical variables overall, they will be **in the order as submitted to the ColumnTransformer.**\n",
    "\n",
    "The original order of columns in the DataFrame **does not matter!**\n",
    "\n",
    "See what happens if I send numerical first and categorical next in the ColumnTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['income', 'age', 'class_6', 'class_7', 'class_8', 'gender_F', 'gender_M']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess = ColumnTransformer([(\"num\", numerical_pipe, numeric_columns),\n",
    "(\"cat\", categorical_pipe, categorical_columns),    \n",
    "], remainder = 'passthrough')\n",
    "\n",
    "preprocess = preprocess.fit(train)\n",
    "train_transformed = preprocess.transform(train)\n",
    "get_transformer_feature_names(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_transformer_feature_names` will retrieve names from `ColumnTransformer` and `Pipeline` in the same order, so one need not worry about mis-naming.\n",
    "\n",
    "What about `remainder = 'passthrough'?` This is used to retain any other column(s) of the dataset that were not mentioned in any `Pipeline`. These columns can be anywhere in between, maybe even intertwined with the model variables. **After transformation, these are pasted at the right end of the dataset in the order in which they appear in the dataset from left to right.** See the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Rich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4    5         6      7     8\n",
       "0  1  0  0  0  1    0         1  Urban  Rich\n",
       "1  0  1  0  1  0  0.8  0.388889  Urban  Poor\n",
       "2  0  0  1  1  0    1         0  Urban  Poor"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.DataFrame({ 'income': [100,500,600],\n",
    "                        'age': [23,12, 5],\n",
    "                      'location':['Urban','Urban','Urban'], \n",
    "                      'nbrhd':['Rich','Poor','Poor'], #Added these 2 new columns that should 'passthrough'\n",
    "                      'class': [6,7,8],\n",
    "                      'gender': ['M','F','F']})\n",
    "preprocess = preprocess.fit(train)\n",
    "train_transformed = preprocess.transform(train)\n",
    "pd.DataFrame(train_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, note that these feature names can't be retrieved using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class_6', 'class_7', 'class_8', 'gender_F', 'gender_M', 'income', 'age']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_transformer_feature_names(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ColumnTransformer was not told what to do with the passthrough columns so they were never tracked. To get all column names, one should explicitly extend the column name list returned by `get_transformer_feature_names`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_6</th>\n",
       "      <th>class_7</th>\n",
       "      <th>class_8</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>location</th>\n",
       "      <th>nbrhd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Rich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_6 class_7 class_8 gender_F gender_M income       age location nbrhd\n",
       "0       1       0       0        0        1      0         1    Urban  Rich\n",
       "1       0       1       0        1        0    0.8  0.388889    Urban  Poor\n",
       "2       0       0       1        1        0      1         0    Urban  Poor"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passed_cols = list(train.columns[~train.columns.isin(numeric_columns + categorical_columns)])\n",
    "pd.DataFrame(train_transformed, columns = get_transformer_feature_names(preprocess) + passed_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, one need not worry about using `preprocess.transform()`on the test set:\n",
    "- If any column from the training set is missing in the test set, even if it's a passthrough column, it will throw a ValueError, saying that a higher number of features were expected\n",
    "- If the column order is different from the training set in any way, even slightly, it will throw a ValueError saying that column ordering must be same as when fitted\n",
    "- If there is any never-before-seen extra column in between, it will throw the same error as above\n",
    "- If there is any never-before-seen extra column at the last, it will let those columns passthrough, but raise a FutureWarning saying that this will fail in sklearn’s next version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Rich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Rich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.94444</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4    5         6      7     8\n",
       "0  1  0  0  0  1  0.6  0.388889  Rural  Rich\n",
       "1  0  1  0  0  1    1  0.555556  Urban  Rich\n",
       "2  0  1  0  1  0  1.6   3.94444  Urban  Poor"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame({ 'income': [400,600,900],\n",
    "                        'age': [12,15, 76],\n",
    "                      'location':['Rural','Urban','Urban'], \n",
    "                      'nbrhd':['Rich','Rich','Poor'],\n",
    "                      'class': [6,7,7],\n",
    "                      'gender': ['M','M','F']})\n",
    "pd.DataFrame(preprocess.transform(test))\n",
    "# Try removing any column, even if it is a passthrough column\n",
    "# Try adding 'occu':['ag','ag','non-ag'] in various locations in between and at the last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly.\n",
    "\n",
    "Another option is to use `pandas.get_dummies()` but it is generally not recommended as your training set (which is larger and richer) might have categories not present in validation and test sets, and so after column transformation the column numbers will not match and the model will fail to predict. The ColumnTransformer object created by sklearn especially takes care that this does not happen using `handle_unknown = “ignore”`\n",
    "\n",
    "You can use `pandas.get_dummies()` if: \n",
    "- categories are broad and less in your data\n",
    "- it is possible for you to create dummies first and split data into train-test second\n",
    "\n",
    "See: http://fastml.com/how-to-use-pd-dot-get-dummies-with-the-test-set/\n",
    "\n",
    "But scaling, encoding and imputation all come together as a package in Pipeline, so I will make a case for it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
